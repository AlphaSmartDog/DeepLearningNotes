{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习[莫烦强化学习笔记](https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/2-1-general-rl/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple example for Reinforcement Learning using table lookup Q-learning method.\n",
    "An agent \"o\" is on the left of a 1 dimensional world, the treasure is on the rightmost location.\n",
    "Run this program and to see how the agent will improve its strategy of finding the treasure.\n",
    "View more on my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "给随机生成器设置seed的目的是每次运行程序得到的随机数的值相同，这样方便测试。\n",
    "numpy.random.seed()不是线程安全的，如果程序中有多个线程最好使用\n",
    "numpy.random.RandomState实例对象来创建或者使用random.seed()来设置相同的随机数种子。\n",
    "\"\"\"\n",
    "np.random.seed(2)  # reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_STATES = 11  # the length of the 1 dimensional world\n",
    "ACTIONS = ['left', 'right']     # available actions\n",
    "EPSILON = 0.9   # greedy police 贪心策略\n",
    "ALPHA = 0.1     # learning rate\n",
    "GAMMA = 0.9    # discount factor\n",
    "MAX_EPISODES = 30   # maximum episodes 最大的回合数\n",
    "FRESH_TIME = 0.3    # fresh time for one move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Q_table_initialization(num_states, actions):\n",
    "    \"\"\"\n",
    "    Q_Table 初始化\n",
    "    基础版本 行-状态 列-行为\n",
    "    \"\"\"\n",
    "    Q_Table = pd.DataFrame(\n",
    "        np.zeros((num_states, len(actions))), # 初始化Q 表格 行-状态 列-行为\n",
    "        columns = actions) # 列名-行为\n",
    "    return Q_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    left  right\n",
       "0    0.0    0.0\n",
       "1    0.0    0.0\n",
       "2    0.0    0.0\n",
       "3    0.0    0.0\n",
       "4    0.0    0.0\n",
       "5    0.0    0.0\n",
       "6    0.0    0.0\n",
       "7    0.0    0.0\n",
       "8    0.0    0.0\n",
       "9    0.0    0.0\n",
       "10   0.0    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for Q_Table_Initialization\n",
    "\n",
    "test = Q_table_initialization(N_STATES, ACTIONS)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action_choice(state, Q_Table):\n",
    "    \"\"\"\n",
    "    在状态state_i 选择行为action\n",
    "    \"\"\"\n",
    "    # 获取状态所有行为\n",
    "    state_actions = Q_Table.iloc[state, :] \n",
    "    # act non-greedy or state-action have no value\n",
    "    if (np.random.uniform() > EPSILON) or (state_actions.all()==0):\n",
    "        action_name = np.random.choice(ACTIONS)\n",
    "    else:\n",
    "        # 获取Q-Tables 最大价值奖励的行为\n",
    "        action_name = state_actions.argmax()\n",
    "    return action_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for choose_action\n",
    "test_2 = action_choice(state=3, Q_Table=test)\n",
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for choose_action\n",
    "test = pd.DataFrame(np.random.uniform(size=(6,2)), columns=ACTIONS)\n",
    "action_choice(2,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_environment_feedback(state, action):\n",
    "    \"\"\"\n",
    "    这是agent如何与环境的互动\n",
    "    This is how agent will interact with the environment\n",
    "    \"\"\"\n",
    "    if action == 'right':\n",
    "        if state == N_STATES - 2: # terminate \n",
    "            next_state = 'terminal' #终止\n",
    "            reward = 1\n",
    "        else:\n",
    "            next_state = state + 1\n",
    "            reward = 0\n",
    "\n",
    "    elif action == 'left':    \n",
    "        reward = 0\n",
    "        if state == 0:\n",
    "            next_state = state\n",
    "        else:\n",
    "            next_state = state - 1\n",
    "    return next_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#test for get_environment_feedback\n",
    "next_state, reward = get_environment_feedback(3, 'right')\n",
    "print (next_state)\n",
    "print (reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_environment(state, episode, step_counter):\n",
    "    \"\"\"\n",
    "    agent 如何与环境 environment 交互\n",
    "    This is how environment be updated\n",
    "    \"\"\" \n",
    "    # 环境表现-列表形式\n",
    "    environment_list = ['-']*(N_STATES-1) + ['T']\n",
    "    \n",
    "    if state == 'terminal': # 终止\n",
    "        interaction = 'episode %s: total_steps = %s' % (episode+1, step_counter)\n",
    "        print ('\\r{}'.format(interaction), end='')\n",
    "        # Python time sleep() 函数推迟调用线程的运行，可通过参数secs指秒数，表示进程挂起的时间。\n",
    "        # t -- 推迟执行的秒数。\n",
    "        time.sleep(5)\n",
    "        # \\r 代表回车，也就是打印头归位，回到某一行的开头。\n",
    "        # \\n代表换行，就是走纸，下一行。\n",
    "        # \\r真正实现了其回车的功能（回到某行开头，把前面的输出覆盖了，\n",
    "        # 其实在PyCharm中是把前面的内容抹去了，不管前面的内容有多长都会被全部抹去）\n",
    "        print('\\r                                ', end='')\n",
    "        \n",
    "    else:\n",
    "        environment_list[state] = 'o'\n",
    "        # Python join() 方法用于将序列中的元素以指定的字符连接生成一个新的字符串。\n",
    "        interaction = ''.join(environment_list)\n",
    "        print ('\\r{}'.format(interaction), end='')\n",
    "        time.sleep(FRESH_TIME)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                "
     ]
    }
   ],
   "source": [
    "# test for update_environment\n",
    "state = 'terminal'\n",
    "episode = 9\n",
    "step_counter = 11\n",
    "update_environment(state, episode, step_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "--o-------T"
     ]
    }
   ],
   "source": [
    "# test for update_environment\n",
    "state = 2\n",
    "episode = 9\n",
    "step_counter = 11\n",
    "update_environment(state, episode, step_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reinforcement_learning():\n",
    "    # Q Learning 表格初始化\n",
    "    q_table = Q_table_initialization(N_STATES, ACTIONS)\n",
    "    # episode 一局游戏的一个回合\n",
    "    for episode in range(MAX_EPISODES):\n",
    "        step_counter = 0 # 计数器初始化\n",
    "        state = 0 # 回合初始化\n",
    "        is_terminated = False # 是否回合结束\n",
    "        update_environment(state, episode, step_counter)\n",
    "        while not is_terminated:\n",
    "            action = action_choice(state, q_table) # 行为选择\n",
    "            next_state, reward = get_environment_feedback(state, action) # agent 行为与环境交互\n",
    "            q_values_eval = q_table.loc[state, action]\n",
    "            if next_state != 'terminal':\n",
    "                q_targets = reward + GAMMA * q_table.iloc[next_state, :].max()\n",
    "            else:\n",
    "                q_targets = reward\n",
    "                is_terminated = True\n",
    "            \n",
    "            q_table.loc[state, action] += ALPHA * (q_targets - q_values_eval) # q_table 更新\n",
    "            state = next_state # 探索者移动到下一个 state\n",
    "            step_counter += 1\n",
    "            update_environment(state, episode, step_counter) # 环境更新\n",
    "            \n",
    "    return q_table  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                "
     ]
    }
   ],
   "source": [
    "q_table = reinforcement_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.652261e-09</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.941277e-10</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.553630e-05</td>\n",
       "      <td>0.004548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.952575e-09</td>\n",
       "      <td>0.016046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.860350e-05</td>\n",
       "      <td>0.047977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.944280e-04</td>\n",
       "      <td>0.120605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.059347e-03</td>\n",
       "      <td>0.258852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.368521e-05</td>\n",
       "      <td>0.478073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.385100e-04</td>\n",
       "      <td>0.735098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.100000e-04</td>\n",
       "      <td>0.957609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            left     right\n",
       "0   1.652261e-09  0.000254\n",
       "1   5.941277e-10  0.001134\n",
       "2   1.553630e-05  0.004548\n",
       "3   2.952575e-09  0.016046\n",
       "4   4.860350e-05  0.047977\n",
       "5   2.944280e-04  0.120605\n",
       "6   6.059347e-03  0.258852\n",
       "7   2.368521e-05  0.478073\n",
       "8   1.385100e-04  0.735098\n",
       "9   8.100000e-04  0.957609\n",
       "10  0.000000e+00  0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
